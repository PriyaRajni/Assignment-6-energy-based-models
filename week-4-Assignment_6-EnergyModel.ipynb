{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391874a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyarajni/Desktop/Pythoncode/MSAI-630-A02/venvMLP/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e7baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ce70de",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 1\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 120\n",
    "\n",
    "STEPS = 60             \n",
    "STEP_SIZE = 10.0       \n",
    "NOISE = 0.005          \n",
    "GRADIENT_CLIP = 0.03   \n",
    "\n",
    "ALPHA = 0.1            \n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "BUFFER_SIZE = 8192     \n",
    "RANDOM_RESTART_RATE = 0.05   \n",
    "\n",
    "LOG_DIR = \"./logs_ebm\"\n",
    "os.makedirs(LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2ef03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_mnist(x):\n",
    "    x = x.astype(\"float32\")\n",
    "    x = (x - 127.5) / 127.5  # [-1, 1]\n",
    "    # pad to 32x32 with -1.0\n",
    "    pad = (IMAGE_SIZE - 28) // 2\n",
    "    x = np.pad(\n",
    "        x,\n",
    "        pad_width=((0, 0), (pad, pad), (pad, pad)),\n",
    "        mode=\"constant\",\n",
    "        constant_values=-1.0,\n",
    "    )\n",
    "    x = np.expand_dims(x, axis=-1)  # (N, 32, 32, 1)\n",
    "    return x\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = preprocess_mnist(x_train)\n",
    "x_test = preprocess_mnist(x_test)\n",
    "\n",
    "train_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(x_train)\n",
    "    .shuffle(10_000, seed=SEED)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febc2b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"energy_network\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"energy_network\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,993</span> (300.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,993\u001b[0m (300.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,993</span> (300.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,993\u001b[0m (300.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_energy_network():\n",
    "    inp = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "    x = layers.Conv2D(16, 5, strides=2, padding=\"same\", activation=\"swish\")(inp)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\", activation=\"swish\")(x)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"swish\")(x)\n",
    "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"swish\")(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"swish\")(x)\n",
    "    out = layers.Dense(1)(x)  # energy\n",
    "    return models.Model(inp, out, name=\"energy_network\")\n",
    "\n",
    "energy_net = build_energy_network()\n",
    "energy_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6dfaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def langevin_sample(model, x_init, steps=STEPS, step_size=STEP_SIZE, noise=NOISE, grad_clip=GRADIENT_CLIP):\n",
    "    x = tf.identity(x_init)\n",
    "\n",
    "    for _ in tf.range(steps):\n",
    "        # Inject small Gaussian noise\n",
    "        x = x + noise * tf.random.normal(tf.shape(x), dtype=x.dtype)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x)\n",
    "            e = model(x, training=False)  # energies\n",
    "            # Sum energies so tape can take gradient wrt x\n",
    "            e_sum = tf.reduce_sum(e)\n",
    "\n",
    "        grads = tape.gradient(e_sum, x)\n",
    "        grads = tf.clip_by_value(grads, -grad_clip, grad_clip)\n",
    "\n",
    "        # Update pixels: x <- x + step_size * grads\n",
    "        x = x + step_size * grads\n",
    "\n",
    "        # Keep within valid range [-1, 1]\n",
    "        x = tf.clip_by_value(x, -1.0, 1.0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7352af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, image_shape):\n",
    "        self.size = int(size)\n",
    "        self.image_shape = tuple(image_shape)\n",
    "        self._buffer = None\n",
    "        self._filled = 0\n",
    "\n",
    "    def init(self):\n",
    "        # Start buffer with random images in [-1,1]\n",
    "        self._buffer = np.random.uniform(-1.0, 1.0, size=(self.size, *self.image_shape)).astype(\"float32\")\n",
    "        self._filled = self.size\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.randint(0, self._filled, size=batch_size)\n",
    "        return self._buffer[idx]\n",
    "\n",
    "    def update(self, samples):\n",
    "        # Overwrite random positions with new samples\n",
    "        samples = samples.numpy() if isinstance(samples, tf.Tensor) else samples\n",
    "        n = samples.shape[0]\n",
    "        idx = np.random.randint(0, self.size, size=n)\n",
    "        self._buffer[idx] = samples\n",
    "\n",
    "buffer = ReplayBuffer(BUFFER_SIZE, (IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
    "buffer.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd96c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBM(tf.keras.Model):\n",
    "    def __init__(self, energy_model, replay_buffer, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.energy_model = energy_model\n",
    "        self.replay_buffer = replay_buffer\n",
    "\n",
    "        # Track metrics\n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.cdiv_tracker = tf.keras.metrics.Mean(name=\"cdiv\")\n",
    "        self.reg_tracker = tf.keras.metrics.Mean(name=\"reg\")\n",
    "        self.real_e_tracker = tf.keras.metrics.Mean(name=\"real_energy\")\n",
    "        self.fake_e_tracker = tf.keras.metrics.Mean(name=\"fake_energy\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.cdiv_tracker, self.reg_tracker, self.real_e_tracker, self.fake_e_tracker]\n",
    "\n",
    "    def sample_negatives(self, batch_size):\n",
    "        # Random restart with small probability; else from replay buffer\n",
    "        use_random = np.random.binomial(1, RANDOM_RESTART_RATE, size=batch_size).astype(bool)\n",
    "        start = self.replay_buffer.sample(batch_size).astype(\"float32\")\n",
    "        if np.any(use_random):\n",
    "            start[use_random] = np.random.uniform(-1.0, 1.0, size=(np.sum(use_random), IMAGE_SIZE, IMAGE_SIZE, CHANNELS)).astype(\"float32\")\n",
    "\n",
    "        start = tf.convert_to_tensor(start)\n",
    "        neg = langevin_sample(self.energy_model, start, steps=STEPS, step_size=STEP_SIZE, noise=NOISE, grad_clip=GRADIENT_CLIP)\n",
    "        return neg\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # data is a batch of real images\n",
    "        x_real = data\n",
    "\n",
    "        # Add small noise to real images (matches reference notebook)\n",
    "        x_real = x_real + NOISE * tf.random.normal(tf.shape(x_real), dtype=x_real.dtype)\n",
    "        x_real = tf.clip_by_value(x_real, -1.0, 1.0)\n",
    "\n",
    "        # Generate negative samples with CD (from replay buffer + Langevin)\n",
    "        batch_size = x_real.shape[0]  # Python int when drop_remainder=True\n",
    "        x_fake = self.sample_negatives(batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute energies for real and fake\n",
    "            x_all = tf.concat([x_real, x_fake], axis=0)\n",
    "            e_all = self.energy_model(x_all, training=True)\n",
    "            e_real, e_fake = tf.split(e_all, num_or_size_splits=2, axis=0)\n",
    "\n",
    "            # Contrastive divergence loss\n",
    "            cdiv_loss = tf.reduce_mean(e_fake) - tf.reduce_mean(e_real)\n",
    "\n",
    "            # Energy regularization (stabilizes training)\n",
    "            reg_loss = ALPHA * tf.reduce_mean(tf.square(e_real) + tf.square(e_fake))\n",
    "\n",
    "            loss = cdiv_loss + reg_loss\n",
    "\n",
    "        grads = tape.gradient(loss, self.energy_model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.energy_model.trainable_variables))\n",
    "\n",
    "        # Update replay buffer with newly generated negatives\n",
    "        self.replay_buffer.update(x_fake)\n",
    "\n",
    "        # Update metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.cdiv_tracker.update_state(cdiv_loss)\n",
    "        self.reg_tracker.update_state(reg_loss)\n",
    "        self.real_e_tracker.update_state(tf.reduce_mean(e_real))\n",
    "        self.fake_e_tracker.update_state(tf.reduce_mean(e_fake))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2107bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SymbolicTensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m ebm = EBM(energy_net, buffer)\n\u001b[32m      2\u001b[39m ebm.compile(\n\u001b[32m      3\u001b[39m     optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n\u001b[32m      4\u001b[39m     run_eagerly=\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# set True if you want easier debugging (slower)\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m history = \u001b[43mebm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Pythoncode/MSAI-630-A02/venvMLP/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mEBM.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.apply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, \u001b[38;5;28mself\u001b[39m.energy_model.trainable_variables))\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Update replay buffer with newly generated negatives\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_fake\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Update metrics\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mself\u001b[39m.loss_tracker.update_state(loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mReplayBuffer.update\u001b[39m\u001b[34m(self, samples)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples):\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# Overwrite random positions with new samples\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     samples = \u001b[43msamples\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(samples, tf.Tensor) \u001b[38;5;28;01melse\u001b[39;00m samples\n\u001b[32m     20\u001b[39m     n = samples.shape[\u001b[32m0\u001b[39m]\n\u001b[32m     21\u001b[39m     idx = np.random.randint(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.size, size=n)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SymbolicTensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "ebm = EBM(energy_net, buffer)\n",
    "ebm.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    run_eagerly=True,   # IMPORTANT\n",
    ")\n",
    "\n",
    "history = ebm.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67d91ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m plt.figure()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m.history[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      3\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mEBM Training Loss (Total Loss)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"EBM Training Loss (Total Loss)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c506be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"cdiv\"], label=\"Contrastive Divergence (mean E_fake - mean E_real)\")\n",
    "plt.plot(history.history[\"reg\"], label=\"Regularization\")\n",
    "plt.title(\"EBM Training Components\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_generated_samples(model, n=16, steps=1000):\n",
    "    x0 = tf.random.uniform((n, IMAGE_SIZE, IMAGE_SIZE, CHANNELS), minval=-1.0, maxval=1.0)\n",
    "    xg = langevin_sample(model, x0, steps=steps, step_size=STEP_SIZE, noise=NOISE, grad_clip=GRADIENT_CLIP)\n",
    "    imgs = (xg.numpy() + 1.0) / 2.0  # back to [0,1]\n",
    "    imgs = np.clip(imgs, 0, 1)\n",
    "\n",
    "    cols = int(np.sqrt(n))\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    plt.figure(figsize=(cols * 2, rows * 2))\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(imgs[i, :, :, 0], cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(f\"Generated Samples (Langevin steps={steps})\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvMLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
